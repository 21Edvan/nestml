# Generated from pynestml/src/main/grammars/org/Tokens.g4 by ANTLR 4.5.1
from antlr4 import *
from io import StringIO


def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u0430\ud6d1\u8206\uad2d\u4417\uaef1\u8d80\uaadd\2\13")
        buf.write("\177\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t")
        buf.write("\7\4\b\t\b\4\t\t\t\4\n\t\n\3\2\3\2\7\2\30\n\2\f\2\16\2")
        buf.write("\33\13\2\3\2\3\2\3\2\3\2\7\2!\n\2\f\2\16\2$\13\2\3\2\3")
        buf.write("\2\3\2\3\2\3\2\3\2\3\2\7\2-\n\2\f\2\16\2\60\13\2\3\2\3")
        buf.write("\2\3\2\5\2\65\n\2\3\2\3\2\3\3\3\3\3\3\5\3<\n\3\3\4\3\4")
        buf.write("\3\4\3\4\3\5\3\5\5\5D\n\5\3\5\3\5\3\5\3\5\3\6\3\6\3\7")
        buf.write("\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3")
        buf.write("\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\5\bb\n\b\3\t\3\t\7\tf\n")
        buf.write("\t\f\t\16\ti\13\t\3\t\5\tl\n\t\3\t\3\t\7\tp\n\t\f\t\16")
        buf.write("\ts\13\t\5\tu\n\t\3\n\5\nx\n\n\3\n\7\n{\n\n\f\n\16\n~")
        buf.write("\13\n\4\".\2\13\3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n\23")
        buf.write("\13\3\2\b\4\2\f\f\17\17\4\2\13\13\"\"\3\2\63;\3\2\62;")
        buf.write("\6\2&&C\\aac|\7\2&&\62;C\\aac|\u008d\2\3\3\2\2\2\2\5\3")
        buf.write("\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2")
        buf.write("\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3\2\2\2\3\64\3\2\2\2")
        buf.write("\5;\3\2\2\2\7=\3\2\2\2\tA\3\2\2\2\13I\3\2\2\2\rK\3\2\2")
        buf.write("\2\17a\3\2\2\2\21k\3\2\2\2\23w\3\2\2\2\25\31\7%\2\2\26")
        buf.write("\30\n\2\2\2\27\26\3\2\2\2\30\33\3\2\2\2\31\27\3\2\2\2")
        buf.write("\31\32\3\2\2\2\32\65\3\2\2\2\33\31\3\2\2\2\34\35\7\61")
        buf.write("\2\2\35\36\7,\2\2\36\"\3\2\2\2\37!\13\2\2\2 \37\3\2\2")
        buf.write("\2!$\3\2\2\2\"#\3\2\2\2\" \3\2\2\2#%\3\2\2\2$\"\3\2\2")
        buf.write("\2%&\7,\2\2&\65\7\61\2\2\'(\7$\2\2()\7$\2\2)*\7$\2\2*")
        buf.write(".\3\2\2\2+-\13\2\2\2,+\3\2\2\2-\60\3\2\2\2./\3\2\2\2.")
        buf.write(",\3\2\2\2/\61\3\2\2\2\60.\3\2\2\2\61\62\7$\2\2\62\63\7")
        buf.write("$\2\2\63\65\7$\2\2\64\25\3\2\2\2\64\34\3\2\2\2\64\'\3")
        buf.write("\2\2\2\65\66\3\2\2\2\66\67\b\2\2\2\67\4\3\2\2\289\7\17")
        buf.write("\2\29<\7\f\2\2:<\t\2\2\2;8\3\2\2\2;:\3\2\2\2<\6\3\2\2")
        buf.write("\2=>\t\3\2\2>?\3\2\2\2?@\b\4\2\2@\b\3\2\2\2AC\7^\2\2B")
        buf.write("D\7\17\2\2CB\3\2\2\2CD\3\2\2\2DE\3\2\2\2EF\7\f\2\2FG\3")
        buf.write("\2\2\2GH\b\5\2\2H\n\3\2\2\2IJ\7<\2\2J\f\3\2\2\2KL\7g\2")
        buf.write("\2LM\7p\2\2MN\7f\2\2N\16\3\2\2\2OP\7v\2\2PQ\7t\2\2QR\7")
        buf.write("w\2\2Rb\7g\2\2ST\7V\2\2TU\7t\2\2UV\7w\2\2Vb\7g\2\2WX\7")
        buf.write("h\2\2XY\7c\2\2YZ\7n\2\2Z[\7u\2\2[b\7g\2\2\\]\7H\2\2]^")
        buf.write("\7c\2\2^_\7n\2\2_`\7u\2\2`b\7g\2\2aO\3\2\2\2aS\3\2\2\2")
        buf.write("aW\3\2\2\2a\\\3\2\2\2b\20\3\2\2\2cg\t\4\2\2df\t\5\2\2")
        buf.write("ed\3\2\2\2fi\3\2\2\2ge\3\2\2\2gh\3\2\2\2hl\3\2\2\2ig\3")
        buf.write("\2\2\2jl\7\62\2\2kc\3\2\2\2kj\3\2\2\2lt\3\2\2\2mq\7\60")
        buf.write("\2\2np\t\5\2\2on\3\2\2\2ps\3\2\2\2qo\3\2\2\2qr\3\2\2\2")
        buf.write("ru\3\2\2\2sq\3\2\2\2tm\3\2\2\2tu\3\2\2\2u\22\3\2\2\2v")
        buf.write("x\t\6\2\2wv\3\2\2\2x|\3\2\2\2y{\t\7\2\2zy\3\2\2\2{~\3")
        buf.write("\2\2\2|z\3\2\2\2|}\3\2\2\2}\24\3\2\2\2~|\3\2\2\2\21\2")
        buf.write("\31\".\64;Cagkqtwz|\3\2\3\2")
        return buf.getvalue()


class Tokens(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]


    SL_COMMENT = 1
    NEWLINE = 2
    WS = 3
    LINE_ESCAPE = 4
    BLOCK_OPEN = 5
    BLOCK_CLOSE = 6
    BOOLEAN_LITERAL = 7
    NUMERIC_LITERAL = 8
    NAME = 9

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "':'", "'end'" ]

    symbolicNames = [ "<INVALID>",
            "SL_COMMENT", "NEWLINE", "WS", "LINE_ESCAPE", "BLOCK_OPEN", 
            "BLOCK_CLOSE", "BOOLEAN_LITERAL", "NUMERIC_LITERAL", "NAME" ]

    ruleNames = [ "SL_COMMENT", "NEWLINE", "WS", "LINE_ESCAPE", "BLOCK_OPEN", 
                  "BLOCK_CLOSE", "BOOLEAN_LITERAL", "NUMERIC_LITERAL", "NAME" ]

    grammarFileName = "Tokens.g4"

    def __init__(self, input=None):
        super().__init__(input)
        self.checkVersion("4.5.1")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


