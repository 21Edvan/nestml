# Generated from pynestml/src/main/grammars/org/Tokens.g4 by ANTLR 4.5.1
# encoding: utf-8
from __future__ import print_function
from antlr4 import *
from io import StringIO


def serializedATN():
    with StringIO() as buf:
        buf.write(u"\3\u0430\ud6d1\u8206\uad2d\u4417\uaef1\u8d80\uaadd\2")
        buf.write(u"\f\u00a7\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6")
        buf.write(u"\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4")
        buf.write(u"\r\t\r\4\16\t\16\4\17\t\17\4\20\t\20\3\2\3\2\7\2$\n\2")
        buf.write(u"\f\2\16\2\'\13\2\3\2\3\2\3\2\3\2\7\2-\n\2\f\2\16\2\60")
        buf.write(u"\13\2\3\2\3\2\3\2\3\2\3\2\3\2\3\2\7\29\n\2\f\2\16\2<")
        buf.write(u"\13\2\3\2\3\2\3\2\5\2A\n\2\3\2\3\2\3\3\3\3\3\3\5\3H\n")
        buf.write(u"\3\3\4\3\4\3\4\3\4\3\5\3\5\5\5P\n\5\3\5\3\5\3\5\3\5\3")
        buf.write(u"\6\3\6\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3")
        buf.write(u"\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\3\b\5\bn\n\b\3")
        buf.write(u"\t\5\tq\n\t\3\t\7\tt\n\t\f\t\16\tw\13\t\3\n\3\n\5\n{")
        buf.write(u"\n\n\3\13\3\13\7\13\177\n\13\f\13\16\13\u0082\13\13\3")
        buf.write(u"\f\3\f\5\f\u0086\n\f\3\r\3\r\5\r\u008a\n\r\3\r\3\r\3")
        buf.write(u"\r\5\r\u008f\n\r\3\r\5\r\u0092\n\r\3\16\3\16\5\16\u0096")
        buf.write(u"\n\16\3\16\3\16\3\17\3\17\5\17\u009c\n\17\3\17\3\17\5")
        buf.write(u"\17\u00a0\n\17\3\20\3\20\6\20\u00a4\n\20\r\20\16\20\u00a5")
        buf.write(u"\4.:\2\21\3\3\5\4\7\5\t\6\13\7\r\b\17\t\21\n\23\13\25")
        buf.write(u"\2\27\f\31\2\33\2\35\2\37\2\3\2\n\4\2\f\f\17\17\4\2\13")
        buf.write(u"\13\"\"\6\2&&C\\aac|\7\2&&\62;C\\aac|\3\2\63;\3\2\62")
        buf.write(u";\4\2GGgg\4\2--//\u00b7\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3")
        buf.write(u"\2\2\2\2\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2")
        buf.write(u"\2\2\2\21\3\2\2\2\2\23\3\2\2\2\2\27\3\2\2\2\3@\3\2\2")
        buf.write(u"\2\5G\3\2\2\2\7I\3\2\2\2\tM\3\2\2\2\13U\3\2\2\2\rW\3")
        buf.write(u"\2\2\2\17m\3\2\2\2\21p\3\2\2\2\23z\3\2\2\2\25|\3\2\2")
        buf.write(u"\2\27\u0085\3\2\2\2\31\u0091\3\2\2\2\33\u0095\3\2\2\2")
        buf.write(u"\35\u0099\3\2\2\2\37\u00a1\3\2\2\2!%\7%\2\2\"$\n\2\2")
        buf.write(u"\2#\"\3\2\2\2$\'\3\2\2\2%#\3\2\2\2%&\3\2\2\2&A\3\2\2")
        buf.write(u"\2\'%\3\2\2\2()\7\61\2\2)*\7,\2\2*.\3\2\2\2+-\13\2\2")
        buf.write(u"\2,+\3\2\2\2-\60\3\2\2\2./\3\2\2\2.,\3\2\2\2/\61\3\2")
        buf.write(u"\2\2\60.\3\2\2\2\61\62\7,\2\2\62A\7\61\2\2\63\64\7$\2")
        buf.write(u"\2\64\65\7$\2\2\65\66\7$\2\2\66:\3\2\2\2\679\13\2\2\2")
        buf.write(u"8\67\3\2\2\29<\3\2\2\2:;\3\2\2\2:8\3\2\2\2;=\3\2\2\2")
        buf.write(u"<:\3\2\2\2=>\7$\2\2>?\7$\2\2?A\7$\2\2@!\3\2\2\2@(\3\2")
        buf.write(u"\2\2@\63\3\2\2\2AB\3\2\2\2BC\b\2\2\2C\4\3\2\2\2DE\7\17")
        buf.write(u"\2\2EH\7\f\2\2FH\t\2\2\2GD\3\2\2\2GF\3\2\2\2H\6\3\2\2")
        buf.write(u"\2IJ\t\3\2\2JK\3\2\2\2KL\b\4\2\2L\b\3\2\2\2MO\7^\2\2")
        buf.write(u"NP\7\17\2\2ON\3\2\2\2OP\3\2\2\2PQ\3\2\2\2QR\7\f\2\2R")
        buf.write(u"S\3\2\2\2ST\b\5\2\2T\n\3\2\2\2UV\7<\2\2V\f\3\2\2\2WX")
        buf.write(u"\7g\2\2XY\7p\2\2YZ\7f\2\2Z\16\3\2\2\2[\\\7v\2\2\\]\7")
        buf.write(u"t\2\2]^\7w\2\2^n\7g\2\2_`\7V\2\2`a\7t\2\2ab\7w\2\2bn")
        buf.write(u"\7g\2\2cd\7h\2\2de\7c\2\2ef\7n\2\2fg\7u\2\2gn\7g\2\2")
        buf.write(u"hi\7H\2\2ij\7c\2\2jk\7n\2\2kl\7u\2\2ln\7g\2\2m[\3\2\2")
        buf.write(u"\2m_\3\2\2\2mc\3\2\2\2mh\3\2\2\2n\20\3\2\2\2oq\t\4\2")
        buf.write(u"\2po\3\2\2\2qu\3\2\2\2rt\t\5\2\2sr\3\2\2\2tw\3\2\2\2")
        buf.write(u"us\3\2\2\2uv\3\2\2\2v\22\3\2\2\2wu\3\2\2\2x{\5\25\13")
        buf.write(u"\2y{\7\62\2\2zx\3\2\2\2zy\3\2\2\2{\24\3\2\2\2|\u0080")
        buf.write(u"\t\6\2\2}\177\t\7\2\2~}\3\2\2\2\177\u0082\3\2\2\2\u0080")
        buf.write(u"~\3\2\2\2\u0080\u0081\3\2\2\2\u0081\26\3\2\2\2\u0082")
        buf.write(u"\u0080\3\2\2\2\u0083\u0086\5\31\r\2\u0084\u0086\5\33")
        buf.write(u"\16\2\u0085\u0083\3\2\2\2\u0085\u0084\3\2\2\2\u0086\30")
        buf.write(u"\3\2\2\2\u0087\u008a\5\25\13\2\u0088\u008a\7\62\2\2\u0089")
        buf.write(u"\u0087\3\2\2\2\u0089\u0088\3\2\2\2\u0089\u008a\3\2\2")
        buf.write(u"\2\u008a\u008b\3\2\2\2\u008b\u0092\5\37\20\2\u008c\u008f")
        buf.write(u"\5\25\13\2\u008d\u008f\7\62\2\2\u008e\u008c\3\2\2\2\u008e")
        buf.write(u"\u008d\3\2\2\2\u008f\u0090\3\2\2\2\u0090\u0092\7\60\2")
        buf.write(u"\2\u0091\u0089\3\2\2\2\u0091\u008e\3\2\2\2\u0092\32\3")
        buf.write(u"\2\2\2\u0093\u0096\5\25\13\2\u0094\u0096\5\31\r\2\u0095")
        buf.write(u"\u0093\3\2\2\2\u0095\u0094\3\2\2\2\u0096\u0097\3\2\2")
        buf.write(u"\2\u0097\u0098\5\35\17\2\u0098\34\3\2\2\2\u0099\u009b")
        buf.write(u"\t\b\2\2\u009a\u009c\t\t\2\2\u009b\u009a\3\2\2\2\u009b")
        buf.write(u"\u009c\3\2\2\2\u009c\u009f\3\2\2\2\u009d\u00a0\5\25\13")
        buf.write(u"\2\u009e\u00a0\7\62\2\2\u009f\u009d\3\2\2\2\u009f\u009e")
        buf.write(u"\3\2\2\2\u00a0\36\3\2\2\2\u00a1\u00a3\7\60\2\2\u00a2")
        buf.write(u"\u00a4\t\7\2\2\u00a3\u00a2\3\2\2\2\u00a4\u00a5\3\2\2")
        buf.write(u"\2\u00a5\u00a3\3\2\2\2\u00a5\u00a6\3\2\2\2\u00a6 \3\2")
        buf.write(u"\2\2\27\2%.:@GOmpsuz\u0080\u0085\u0089\u008e\u0091\u0095")
        buf.write(u"\u009b\u009f\u00a5\3\2\3\2")
        return buf.getvalue()


class Tokens(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]


    SL_COMMENT = 1
    NEWLINE = 2
    WS = 3
    LINE_ESCAPE = 4
    BLOCK_OPEN = 5
    BLOCK_CLOSE = 6
    BOOLEAN_LITERAL = 7
    NAME = 8
    INTEGER = 9
    FLOAT = 10

    modeNames = [ u"DEFAULT_MODE" ]

    literalNames = [ u"<INVALID>",
            u"':'", u"'end'" ]

    symbolicNames = [ u"<INVALID>",
            u"SL_COMMENT", u"NEWLINE", u"WS", u"LINE_ESCAPE", u"BLOCK_OPEN", 
            u"BLOCK_CLOSE", u"BOOLEAN_LITERAL", u"NAME", u"INTEGER", u"FLOAT" ]

    ruleNames = [ u"SL_COMMENT", u"NEWLINE", u"WS", u"LINE_ESCAPE", u"BLOCK_OPEN", 
                  u"BLOCK_CLOSE", u"BOOLEAN_LITERAL", u"NAME", u"INTEGER", 
                  u"NON_ZERO_INTEGER", u"FLOAT", u"POINT_FLOAT", u"EXPONENT_FLOAT", 
                  u"EXPONENT", u"FRACTION" ]

    grammarFileName = u"Tokens.g4"

    def __init__(self, input=None):
        super(Tokens, self).__init__(input)
        self.checkVersion("4.5.1")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


